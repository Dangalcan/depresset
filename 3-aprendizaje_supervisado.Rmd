---
title: "Estudio sobre la depresión estudiantil. Grupo 5. Aprendizaje supervisado"
author: "Miguel Encina Martinez, Daniel Galván Cancio, Jaime Linares Barrera, Daniel Vela Camacho"
output:
  html_document:
    toc: true
    toc_float: true
    # number_sections: true
---

```{r}
# install.packages("glmnet")
# install.packages("xgboost")
```

```{r}
library(caret)
library(dplyr)
library(rpart.plot)
library(glmnet)
library(xgboost)
```

```{r}
df_factors <- read.csv("./data/student_depression_clean_factors.csv", stringsAsFactors = TRUE)
df_norm <- read.csv("./data/student_depression_normalized.csv")
```

```{r}
df_factors <- df_factors %>%
  mutate(
    Had.suicidal.thoughts = ifelse(Had.suicidal.thoughts == 1, "Yes", "No"),
    Family.History.Mental.Illness = ifelse(Family.History.Mental.Illness == 1, "Yes", "No"),
    Depression = ifelse(Depression == 1, "Yes", "No")
  )

df_factors$Had.suicidal.thoughts      <- factor(df_factors$Had.suicidal.thoughts,
                                                levels = c("Yes", "No"))
df_factors$Family.History.Mental.Illness <- factor(df_factors$Family.History.Mental.Illness,
                                                   levels = c("Yes", "No"))
df_factors$Depression <- factor(df_factors$Depression,
                                levels = c("Yes", "No"))

df_norm$Depression <- ifelse(df_norm$Depression == 1, "Yes", "No")
df_norm$Depression <- factor(df_norm$Depression,
                             levels = c("Yes", "No"))
```

```{r}
global_control <- trainControl(
  method = "cv", 
  number = 10, 
  classProbs = TRUE, 
  summaryFunction = twoClassSummary, 
  savePredictions = "final"
)
```

```{r}
tree_grid <- expand.grid(cp = seq(0.001, 0.05, by = 0.002))

set.seed(123)
tree_model <- train(
  Depression ~ ., 
  data = df_factors, 
  method = "rpart", 
  trControl = global_control, 
  tuneGrid = tree_grid, 
  metric = "ROC"
)

print(tree_model)
```

```{r}
set.seed(123)
glm_model <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "glm", 
  trControl = global_control, 
  metric = "ROC"
)

print(glm_model)
```

```{r}
# Modelo GLM con regularización (glmnet)
glmnet_grid <- expand.grid(alpha = 0:1, lambda = seq(0.0001, 1, length = 20))

set.seed(123)
glmnet_model <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "glmnet", 
  trControl = global_control, 
  tuneGrid = glmnet_grid, 
  metric = "ROC"
)

print(glmnet_model)
```

```{r}
# Modelo XGBoost (xgbTree)
grid_xgb <- expand.grid(
  nrounds = c(50, 100, 150),
  max_depth = c(3, 6, 9),
  eta = c(0.01, 0.1, 0.3),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

set.seed(123)
xgb_model <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "xgbTree", 
  trControl = global_control, 
  tuneGrid = grid_xgb, 
  metric = "ROC"
)

print(xgb_model)
```

```{r}
knn_grid <- expand.grid(k = seq(5, 35, by = 2))

set.seed(123)
knn_model <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "knn", 
  trControl = global_control, 
  tuneGrid = knn_grid, 
  metric = "ROC"
)

print(knn_model)
```

```{r}
model_list <- list(
  Arbol = tree_model,
  GLM = glm_model,
  GLMNet = glmnet_model,
  XGBoost = xgb_model,
  KNN = knn_model
)

comparison_results <- resamples(model_list)
summary(comparison_results)
```

```{r}
xyplot(comparison_results)

bwplot(comparison_results, metric = "ROC")
dotplot(comparison_results, metric = "ROC")
```

```{r}
rpart.plot(tree_model$finalModel, 
           extra = 106, 
           box.palette = "RdGn",
           main = "Árbol de Decisión: Factores de Depresión")
```

```{r}
varImp(tree_model)
```

```{r}

```

```{r}

```
