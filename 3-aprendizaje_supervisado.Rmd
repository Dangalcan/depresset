---
title: "Estudio sobre la depresión estudiantil. Grupo 5. Aprendizaje supervisado"
author: "Miguel Encina Martinez, Daniel Galván Cancio, Jaime Linares Barrera, Daniel Vela Camacho"
output:
  html_document:
    toc: true
    toc_float: true
    # number_sections: true
---

```{r}
# install.packages("glmnet")
# install.packages("xgboost")
```

```{r}
library(caret)
library(dplyr)
library(rpart.plot)
library(glmnet)
library(xgboost)
```

```{r}
df_factors <- read.csv("./data/student_depression_clean_factors.csv", stringsAsFactors = TRUE)
df_norm <- read.csv("./data/student_depression_normalized.csv")
```

```{r}
df_factors <- df_factors %>%
  mutate(
    Had.suicidal.thoughts = ifelse(Had.suicidal.thoughts == 1, "Yes", "No"),
    Family.History.Mental.Illness = ifelse(Family.History.Mental.Illness == 1, "Yes", "No"),
    Depression = ifelse(Depression == 1, "Yes", "No")
  )

df_factors$Had.suicidal.thoughts      <- factor(df_factors$Had.suicidal.thoughts,
                                                levels = c("Yes", "No"))
df_factors$Family.History.Mental.Illness <- factor(df_factors$Family.History.Mental.Illness,
                                                   levels = c("Yes", "No"))
df_factors$Depression <- factor(df_factors$Depression,
                                levels = c("Yes", "No"))

df_norm$Depression <- ifelse(df_norm$Depression == 1, "Yes", "No")
df_norm$Depression <- factor(df_norm$Depression,
                             levels = c("Yes", "No"))
```

```{r}
control_global <- trainControl(
  method = "cv", 
  number = 10, 
  classProbs = TRUE, 
  summaryFunction = twoClassSummary, 
  savePredictions = "final"
)
```

```{r}
grid_arbol <- expand.grid(cp = seq(0.001, 0.05, by = 0.002))

set.seed(123)
modelo_arbol <- train(
  Depression ~ ., 
  data = df_factors, 
  method = "rpart", 
  trControl = control_global, 
  tuneGrid = grid_arbol, 
  metric = "ROC"
)

print(modelo_arbol)
```

```{r}
set.seed(123)
modelo_glm <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "glm", 
  trControl = control_global, 
  metric = "ROC"
)

print(modelo_glm)
```

```{r}
# Modelo GLM con regularización (glmnet)
grid_glmnet <- expand.grid(alpha = 0:1, lambda = seq(0.0001, 1, length = 20))

set.seed(123)
modelo_glmnet <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "glmnet", 
  trControl = control_global, 
  tuneGrid = grid_glmnet, 
  metric = "ROC"
)

print(modelo_glmnet)
```

```{r}
# Modelo XGBoost (xgbTree)
grid_xgb <- expand.grid(
  nrounds = c(50, 100, 150),
  max_depth = c(3, 6, 9),
  eta = c(0.01, 0.1, 0.3),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

set.seed(123)
modelo_xgb <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "xgbTree", 
  trControl = control_global, 
  tuneGrid = grid_xgb, 
  metric = "ROC"
)

print(modelo_xgb)
```

```{r}
grid_knn <- expand.grid(k = seq(5, 35, by = 2))

set.seed(123)
modelo_knn <- train(
  Depression ~ ., 
  data = df_norm, 
  method = "knn", 
  trControl = control_global, 
  tuneGrid = grid_knn, 
  metric = "ROC"
)

print(modelo_knn)
```

```{r}
model_list <- list(
  Arbol = modelo_arbol,
  GLM = modelo_glm,
  GLMNet = modelo_glmnet,
  XGBoost = modelo_xgb,
  KNN = modelo_knn
)

resultados_comparativa <- resamples(model_list)
summary(resultados_comparativa)
```

```{r}
xyplot(resultados_comparativa)

bwplot(resultados_comparativa, metric = "ROC")
dotplot(resultados_comparativa, metric = "ROC")
```

```{r}
rpart.plot(modelo_arbol$finalModel, 
           extra = 106, 
           box.palette = "RdGn",
           main = "Árbol de Decisión: Factores de Depresión")
```

```{r}
varImp(modelo_arbol)
```

```{r}

```

```{r}

```
